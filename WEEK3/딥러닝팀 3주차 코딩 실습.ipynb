{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9LFysohORkY"
   },
   "source": [
    "# **ë”¥ëŸ¬ë‹íŒ€ í´ë¦°ì—… 3ì£¼ì°¨ ì½”ë”© ì‹¤ìŠµ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaZb2cWGgT4Z"
   },
   "source": [
    "> ğŸ–¥**Produced by ê¹€ì˜ˆì°¬ (feat. ì§€ë©˜, êµ¬ê¸€ë§)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SeAlcg8Oai0"
   },
   "source": [
    "---\n",
    "> 3ì£¼ì°¨ì—ëŠ” ìì—°ì–´ì²˜ë¦¬(NLP) ë¶„ì•¼ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•´ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤. \n",
    "\n",
    "> NLPì—ì„œëŠ” RNNì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ëª¨ë¸ë“¤ì´ ì£¼ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ, ì˜¤ëŠ˜ì€ Attention ê¸°ë²•ì„ ì ìš©í•œ Seq2Seq ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì˜ì–´ì™€ í•œêµ­ì–´ ê°„ì˜ ê¸°ê³„ë²ˆì—­ ê³¼ì œë¥¼ ìˆ˜í–‰í•´ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "> ë”ë¶ˆì–´, ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•  ë•ŒëŠ” ë¬¼ë¡ , ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ í•™ìŠµí•  ë•Œë„ ì‚¬ìš©ê°€ëŠ¥í•œ Tensorboardë¼ëŠ” ê²ƒì„ ì‚¬ìš©í•´ë³¼ ê²ƒì…ë‹ˆë‹¤. TensorboardëŠ” ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì—ì„œ lossë‚˜ ì •í™•ë„, íŒŒë¼ë¯¸í„°ì˜ ê°’ ë“±ì„ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ê¸°ëŠ¥ì´ë©°, tensorflowë¼ëŠ” ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì˜ ê¸°ëŠ¥ì´ì§€ë§Œ pytorchì—ì„œë„ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTnGF5KTTvgo"
   },
   "source": [
    "### **0-1) Drive Mount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21348,
     "status": "ok",
     "timestamp": 1647422860633,
     "user": {
      "displayName": "ê¹€ì˜ˆì°¬",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06067702609339936211"
     },
     "user_tz": -540
    },
    "id": "5IKSpK32UrHF",
    "outputId": "40244801-eb8f-4ba8-8788-90c517cac126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Drive Mount\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Working Directory ë³€ê²½\n",
    "\n",
    "import os\n",
    "\n",
    "directory = \"\" # íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
    "path = \"/content/gdrive/My Drive/\" + directory\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlnDSgf1ZJax"
   },
   "source": [
    "### **0-2) í•œê¸€ ê¹¨ì§ í˜„ìƒ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17445,
     "status": "ok",
     "timestamp": 1647422884122,
     "user": {
      "displayName": "ê¹€ì˜ˆì°¬",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06067702609339936211"
     },
     "user_tz": -540
    },
    "id": "8PV5BA5sZJt5",
    "outputId": "0d32a898-7f6a-438f-b989-d7ea47d09978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package fonts-nanum.\n",
      "(Reading database ... 155335 files and directories currently installed.)\n",
      "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
      "Unpacking fonts-nanum (20170925-1) ...\n",
      "Selecting previously unselected package fonts-nanum-eco.\n",
      "Preparing to unpack .../fonts-nanum-eco_1.000-6_all.deb ...\n",
      "Unpacking fonts-nanum-eco (1.000-6) ...\n",
      "Selecting previously unselected package fonts-nanum-extra.\n",
      "Preparing to unpack .../fonts-nanum-extra_20170925-1_all.deb ...\n",
      "Unpacking fonts-nanum-extra (20170925-1) ...\n",
      "Selecting previously unselected package fonts-nanum-coding.\n",
      "Preparing to unpack .../fonts-nanum-coding_2.5-1_all.deb ...\n",
      "Unpacking fonts-nanum-coding (2.5-1) ...\n",
      "Setting up fonts-nanum-extra (20170925-1) ...\n",
      "Setting up fonts-nanum (20170925-1) ...\n",
      "Setting up fonts-nanum-coding (2.5-1) ...\n",
      "Setting up fonts-nanum-eco (1.000-6) ...\n",
      "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
      "NanumBarunGothic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install fonts-nanum* -qq\n",
    "\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "fm._rebuild()\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "font = fm.FontProperties(fname=path, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwbnvbJgvQ5H"
   },
   "source": [
    "### **0-3) ì‹œë“œ ê³ ì •**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-q3_AUZvTMx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed: int = 824):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "random_state = 824\n",
    "seed_everything(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPwaoPTKWEoy"
   },
   "source": [
    "## **1. ë°ì´í„° ì „ì²˜ë¦¬**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZFkaDSgWJwV"
   },
   "source": [
    "---\n",
    "> ì˜ì–´ì™€ í•œêµ­ì–´ì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ eng_to_kor.txt í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ«ì ë°ì´í„°ë¡œ ë°”ê¿”ì£¼ëŠ” classë¥¼ êµ¬í˜„í•˜ì—¬ Seq2Seqì— ëŒ€ì…í•  ìˆ˜ ìˆëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ë³¼ ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "> 3ì£¼ì°¨ í´ë¦°ì—…ì—ì„œ ë°°ìš´ ì„ë² ë”©(Embedding) ë“±ì„ ë– ì˜¬ë ¤ ë´…ì‹œë‹¤!\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p89TDpMkUQ4k"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzJFqr2TarOG"
   },
   "source": [
    "### **1-1) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "855AUoTBa4DL"
   },
   "source": [
    "---\n",
    "> ì˜¤ëŠ˜ ë§Œë“¤ì–´ë³¼ ê¸°ê³„ë²ˆì—­ ëª¨ë¸ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë°ì´í„°ì— ì–´ë–¤ ë¬¸ì¥ë“¤ì´ ìˆëŠ”ì§€ í•œ ë²ˆ í™•ì¸í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "> ì•„ë˜ì˜ 15ê°œ ë¬¸ì¥ì€ ë§¤ìš° ì§§ì§€ë§Œ, í•´ë‹¹ .txt íŒŒì¼ì—ëŠ” ì´ë ‡ê²Œ ì§§ì€ ë¬¸ì¥ë¶€í„° ê¸´ ë¬¸ì¥ê¹Œì§€ ì—¬ëŸ¬ê°€ì§€ ë¬¸ì¥ë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3Ywi6SwbqF9"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "data = open(\"./test/PSAT/3ì£¼ì°¨ ì½”ë”©ì‹¤ìŠµ/eng_to_kor.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1647067047548,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "Ux2mLn2Qavs_",
    "outputId": "afe0669c-3164-49a7-ab24-20ddd2d4a75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tê°€.\n",
      "\n",
      "Hi.\tì•ˆë…•.\n",
      "\n",
      "Run!\të›°ì–´!\n",
      "\n",
      "Run.\të›°ì–´.\n",
      "\n",
      "Who?\tëˆ„êµ¬?\n",
      "\n",
      "Wow!\tìš°ì™€!\n",
      "\n",
      "Fire!\tì´!\n",
      "\n",
      "Help!\të„ì™€ì¤˜!\n",
      "\n",
      "Jump!\tì í”„!\n",
      "\n",
      "Jump.\tì í”„í•´.\n",
      "\n",
      "Wait!\tê¸°ë‹¤ë ¤!\n",
      "\n",
      "Wait!\tì ê¹!\n",
      "\n",
      "Wait.\tê¸°ë‹¤ë ¤.\n",
      "\n",
      "Begin.\tì‹œì‘í•´.\n",
      "\n",
      "Hello!\tì•ˆë…•!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° í™•ì¸\n",
    "\n",
    "for i in range(15):\n",
    "    print(data.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvD9eRrrcJ-p"
   },
   "source": [
    "### **1-2) Word Indexing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxOyp_lzcMpt"
   },
   "source": [
    "---\n",
    "> Seq2SeqëŠ” RNNì„ ë² ì´ìŠ¤ë¡œ í•˜ëŠ” Encoder-Decoder êµ¬ì¡°ì´ê¸° ë•Œë¬¸ì— ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ì´ ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ìˆœì°¨ì ìœ¼ë¡œ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ì¤„ ì˜ˆì •ì¸ë°, ì´ë¥¼ Word Indexingì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AE5g2fIdcuAz"
   },
   "outputs": [],
   "source": [
    "# Word Indexingì„ ìœ„í•œ class êµ¬í˜„\n",
    "\n",
    "SOS_token = 0 # Start of Sentence í† í° (Decoderì˜ ì²« ì…ë ¥)\n",
    "EOS_token = 1 # End of Sentence í† í° (Decoderì˜ ë§ˆì§€ë§‰ ì¶œë ¥)\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    # __init__ í•¨ìˆ˜ëŠ” ì´ classì˜ ê°ì²´ê°€ ì²˜ìŒ ì •ì˜ë˜ëŠ” ìˆœê°„ ì•„ë˜ì˜ dictionaryë“¤ì´ ìë™ìœ¼ë¡œ ìƒì„±ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS ì™€ EOS í¬í•¨\n",
    "\n",
    "    # ë¬¸ì¥ì„ ì…ë ¥ë°›ì•„ ë„ì–´ì“°ê¸° ë‹¨ìœ„ë¡œ ëŠê³ , ì—¬ê¸°ì„œ ì–»ì€ ë‹¨ì–´ë“¤ì„ dictionaryì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    # ë¬¸ì¥ ì†ì— ìˆëŠ” ë‹¨ì–´ë“¤ì„ dictionaryì— ì €ì¥í•˜ëŠ” ë™ì‹œì— ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSC0C_uFc-Pg"
   },
   "source": [
    "### **1-3) ë°ì´í„° ì •ì œ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFnd87_IdEYQ"
   },
   "source": [
    "---\n",
    "> 3ì£¼íƒ€ í´ë¦°ì—…ì—ì„œ ë°°ì› ë“¯ì´, ìì—°ì–´ë¥¼ ì „ì²˜ë¦¬í•  ë•ŒëŠ” ì˜ë¯¸ë¥¼ í•´ì„í•˜ëŠ” ê²ƒì— ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” ìš”ì†Œë“¤ì„ ìµœëŒ€í•œ ì œê±°í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´, ê³ ìœ ëª…ì‚¬ ë“±ì„ ì œì™¸í•œ ë‹¨ì–´ë“¤ì€ ì†Œë¬¸ì/ëŒ€ë¬¸ì ì—¬ë¶€ê°€ ì˜ë¯¸ì— ì˜í–¥ì„ ë¼ì¹˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì œê±°í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "> ì§€ê¸ˆì€ ê°„ë‹¨í•œ ë²ˆì—­ ëª¨ë¸ë§Œ êµ¬í˜„í•˜ëŠ” ê²ƒì´ë¯€ë¡œ, êµ¬ë‘ì ë§Œ ì œê±°í•´ì£¼ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgczcqGGd7MM"
   },
   "outputs": [],
   "source": [
    "# ë¬¸ìê°€ ì•„ë‹Œ ë¬¸ì ì œê±° (ì˜ë¯¸ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ” ìš”ì†Œë“¤ ì œê±°)\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTXKaeUsj2js"
   },
   "source": [
    "### **1-4) ë°ì´í„° ë¶„ë¦¬**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfDg311Oj66R"
   },
   "source": [
    "---\n",
    "> ì—¬ê¸°ì„œ ë§í•˜ëŠ” ë°ì´í„° ë¶„ë¦¬ë€, ì˜ì–´ì™€ í•œêµ­ì–´ ë°ì´í„°ê°€ ëª¨ë‘ ë“¤ì–´ìˆëŠ” .txt ë°ì´í„°ë¥¼ ì˜ì–´ ë°ì´í„°ì…‹ê³¼ í•œêµ­ì–´ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í•œ ë§ˆë””ë¡œ, (X, y) í˜•íƒœë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "> í•™ìŠµì˜ í¸ì˜ë¥¼ ìœ„í•´ ì¢…ë£Œ ë¶€í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ì´ 20ë‹¨ì–´ ì´ë‚´ì˜ ë¬¸ì¥ì— ëŒ€í•´ì„œë§Œ í•™ìŠµì„ ì§„í–‰í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cji6aQLwjbgW"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë°ì´í„° ë¶„ë¦¬\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # íŒŒì¼ì„ ì½ê³  ì¤„ë¡œ ë¶„ë¦¬\n",
    "    lines = open('./test/PSAT/3ì£¼ì°¨ ì½”ë”©ì‹¤ìŠµ/%s_to_%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # ëª¨ë“  ì¤„ì„ ìŒìœ¼ë¡œ ë¶„ë¦¬í•˜ê³  ì •ê·œí™”(êµ¬ë‘ì  ì œê±°)\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # ìŒì„ ë’¤ì§‘ê³ , Lang ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    if reverse: \n",
    "        pairs = [list(reversed(p)) for p in pairs]    # í˜„ì¬ ëª¨ë¸ì€ ì˜ì–´ --> í•œêµ­ì–´ì´ì§€ë§Œ, reverseë¥¼ ì ìš©í•˜ë©´ í•œêµ­ì–´ --> ì˜ì–´ê°€ ë©ë‹ˆë‹¤!\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9Ty02XCRs7Q"
   },
   "outputs": [],
   "source": [
    "# ì˜ì–´ì™€ í•œêµ­ì–´ ëª¨ë‘ 20 ë‹¨ì–´ ì´ë‚´ë¡œ ì„¤ì •\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC7uKT3fsQWs"
   },
   "source": [
    "### **1-5) DataLoader ì¤€ë¹„**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOkozla-sWcH"
   },
   "source": [
    "---\n",
    "> ì•ì„œ ë§Œë“  classë“¤ê³¼ í•¨ìˆ˜ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢…ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°˜í™˜í•´ì£¼ëŠ” Loaderë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ìŒì˜ ì ˆì°¨ì— ë”°ë¼ ìš°ë¦¬ê°€ ëª¨ë¸ì— ì‚¬ìš©í•  ë°ì´í„°ë“¤ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "1.   í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ë“¤ì¸ í›„ ì¤„ë¡œ ë¶„ë¦¬í•˜ë©°, ì˜ì–´ì™€ í•œêµ­ì–´ì˜ ìŒìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤. \n",
    "2.   í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ê³ , ê¸¸ì´ê°€ 20 ë‹¨ì–´ê°€ ë„˜ëŠ” ë¬¸ì¥ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "3.   (ì˜ì–´, í•œêµ­ì–´)ì˜ ìƒì„ ì´ë£¬ ë¬¸ì¥ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¨ì–´ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1647067064803,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "peZY_Vd9TJvs",
    "outputId": "d53718bc-bd0f-4630-9b4e-cefb3cda1e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 3798 sentence pairs\n",
      "Trimmed to 3792 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2986\n",
      "kor 5737\n",
      "[\"Let's hear the rest of the story .\", 'ì´ì•¼ê¸°ë¥¼ ë§ˆì € ë“¤ì–´ ë´…ì‹œë‹¤ .']\n"
     ]
    }
   ],
   "source": [
    "# ì…ë ¥ ë°ì´í„°ì˜ í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ë°˜í™˜\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'kor', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MU1XtMLQWNlH"
   },
   "outputs": [],
   "source": [
    "# ì…ì¶œë ¥ ë°ì´í„° ëª¨ë‘ tensorë¡œ ë³€í™˜ + sos & eos í† í° ë„£ê¸°\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym3xQ41HuY-H"
   },
   "source": [
    "## **3. ëª¨ë¸ë§**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MpsUd8Sub6P"
   },
   "source": [
    "---\n",
    "> ì´ì œ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤! ì €ë²ˆì£¼ì™€ ë§ˆì°¬ê°€ì§€ë¡œ Pytorchë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ êµ¬í˜„í•  ì˜ˆì •ì´ë©°, Encoder-Decoder êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” Seq2Seq ëª¨ë¸ì— Attention ê¸°ë²•ì„ ì¶”ê°€í•  ì˜ˆì •ì…ë‹ˆë‹¤. ë”°ë¼ì„œ, í¬ê²Œ Encoder, Decoder 2ê°€ì§€ ëª¨ë¸ì„ ë§Œë“  í›„ ì´ 2ê°€ì§€ ëª¨ë¸ì„ ë³‘í•©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ì„ êµ¬í˜„í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwNj0q-evA1m"
   },
   "source": [
    "### **3-1) ëª¨ë¸ ì •ì˜**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCBPpnVfvPYV"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "1. Encoder: ì˜ì–´ ì…ë ¥ ë¬¸ì¥ë“¤ì„ ì„ë² ë”©í•œ í›„ GRU ìœ ë‹›ìœ¼ë¡œ í†µê³¼ì‹œí‚µë‹ˆë‹¤. \n",
    "   * ì˜ì–´ ì…ë ¥ ë¬¸ì¥ë“¤ì„ ì„ë² ë”©(ë²¡í„°ì˜ í˜•íƒœë¡œ í‘œí˜„)\n",
    "   * GRU ìœ ë‹›ì„ í†µê³¼ì‹œì¼œ Hidden State ì—°ì‚°\n",
    "   * Hidden Stateë¥¼ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜\n",
    "\n",
    "\n",
    "2. Decoder: Encoderì˜ ë§ˆì§€ë§‰ Hidden Stateì™€ í•œêµ­ì–´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë²ˆì—­\n",
    "   * í•œêµ­ì–´ ì…ë ¥ ë¬¸ì¥ë“¤ì„ ì„ë² ë”©\n",
    "   * GRU ìœ ë‹›ì„ í†µê³¼ì‹œì¼œ Hidden Stateì™€ Output ì—°ì‚°\n",
    "   * ë§¤ ì‹œì  Outputì„ ì°¨ë¡€ë¡œ FC Layer, Softmaxì— í†µê³¼ì‹œì¼œ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ë²ˆì—­ëœ ë‹¨ì–´ ë°˜í™˜\n",
    "\n",
    "\n",
    "3. Attention Decoder: Decoderì™€ êµ¬ì¡°ëŠ” ë™ì¼í•˜ì§€ë§Œ Attention ê¸°ë²• ì ìš©\n",
    "   * í´ë¦°ì—…ì—ì„œ ë°°ìš´ Dot Product Attention ê¸°ë²• ëŒ€ì‹  FC Layerë¥¼ ì‚¬ìš©í•˜ì—¬ Attention Scoreë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²• ì ìš©\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02kV44HKvAUW"
   },
   "outputs": [],
   "source": [
    "# Encoder ì •ì˜\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)  # deviceëŠ” 2ì£¼ì°¨ ì‹¤ìŠµì—ì„œ ë³„ë„ë¡œ .to('cuda')ë¥¼ ëª¨ë¸ ë‚´ì—ì„œ ë¯¸ë¦¬ í•˜ëŠ” ê²ƒ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SH2prlspPO9l"
   },
   "outputs": [],
   "source": [
    "# Decoder ì •ì˜ - Seq2Seq\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6mUhzHbPdTo"
   },
   "outputs": [],
   "source": [
    "# Attention Decoder ì •ì˜\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647067159521,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "tfvJhW6i2jb0",
    "outputId": "ba083659-7acc-4cf8-a693-46fca62dbda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(20, 128)\n",
      "  (gru): GRU(128, 128)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(EncoderRNN(20, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m-QG0Luygd8"
   },
   "source": [
    "### **3-2) ëª¨ë¸ ê°œìš” í™•ì¸**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1647067564070,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "uDZv7V17j8D7",
    "outputId": "b4f0f650-9ee3-49fb-e47a-82a0eb326c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "EncoderRNN                               --\n",
       "â”œâ”€Embedding: 1-1                         2,560\n",
       "â”œâ”€GRU: 1-2                               99,072\n",
       "=================================================================\n",
       "Total params: 101,632\n",
       "Trainable params: 101,632\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(EncoderRNN(20, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1647067605284,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "eoowh7Bp4JzX",
    "outputId": "38af27e0-85b9-45b4-baa3-b737a59883ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "DecoderRNN                               --\n",
       "â”œâ”€Embedding: 1-1                         2,560\n",
       "â”œâ”€GRU: 1-2                               99,072\n",
       "â”œâ”€Linear: 1-3                            2,580\n",
       "â”œâ”€LogSoftmax: 1-4                        --\n",
       "=================================================================\n",
       "Total params: 104,212\n",
       "Trainable params: 104,212\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(DecoderRNN(128, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647067625322,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "zHhxfM7i4MUJ",
    "outputId": "7b85c634-a874-4a51-e48c-4afedd189e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "AttnDecoderRNN                           --\n",
       "â”œâ”€Embedding: 1-1                         2,560\n",
       "â”œâ”€Linear: 1-2                            5,140\n",
       "â”œâ”€Linear: 1-3                            32,896\n",
       "â”œâ”€Dropout: 1-4                           --\n",
       "â”œâ”€GRU: 1-5                               99,072\n",
       "â”œâ”€Linear: 1-6                            2,580\n",
       "=================================================================\n",
       "Total params: 142,248\n",
       "Trainable params: 142,248\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(AttnDecoderRNN(128, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6SKAGhYDuzx"
   },
   "source": [
    "## **4. í•™ìŠµ ë° í‰ê°€**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6Be4DgdD6MH"
   },
   "source": [
    "### **4-1) ëª¨ë¸ í•™ìŠµ ì¤€ë¹„**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2310nWuPm4Yr"
   },
   "outputs": [],
   "source": [
    "# train í•¨ìˆ˜ ì •ì˜ - êµì‚¬ê°•ìš” í¬í•¨!\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing í¬í•¨: ëª©í‘œë¥¼ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Teacher forcing ë¯¸í¬í•¨: ìì‹ ì˜ ì˜ˆì¸¡ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ë¶€ë¶„ì„ íˆìŠ¤í† ë¦¬ì—ì„œ ë¶„ë¦¬\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuHh07UDZR2j"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiCr0evwWjhJ"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµ ì‹œê°„ ë° ì†Œìš” ì‹œê°„ ê³„ì‚°\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNwm1IUP4xDL"
   },
   "outputs": [],
   "source": [
    "# Tensorboard ì‚¬ìš© ì¤€ë¹„\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB3tdkytW3O0"
   },
   "outputs": [],
   "source": [
    "# ì „ì²´ í•™ìŠµ Flow ì™„ì„±!\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every ë§ˆë‹¤ ì´ˆê¸°í™”\n",
    "    plot_loss_total = 0   # plot_every ë§ˆë‹¤ ì´ˆê¸°í™”\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) # Encoderì˜ Optim\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) # Decoderì˜ Optim\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        writer.add_scalar(\"Loss\", loss, iter)                            # Encoderì˜ loss ì €ì¥\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDN6nXV3MngM"
   },
   "source": [
    "### **4-2) ëª¨ë¸ í•™ìŠµ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "griSjxndOXCV"
   },
   "source": [
    "-----\n",
    "> ë³¸ê²©ì ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤. 1ì£¼ì°¨ì—ì„œ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´, ë”¥ëŸ¬ë‹ì—ì„œ í•™ìŠµì€ ë³´í†µ ì†ì‹¤í•¨ìˆ˜ì˜ ê°’ì„ ìµœì†Œí™”ì‹œí‚¤ëŠ” ê³¼ì •ì„ ë”°ë¼ ì´ë£¨ì–´ì§€ë©°, ê·¸ ê³¼ì •ì—ì„œ í•™ìŠµ ë°ì´í„° ë° ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì˜ ì •í™•ë„ê°€ ì˜¬ë¼ê°€ê²Œ ë©ë‹ˆë‹¤. ë•Œë¬¸ì—, ì†ì‹¤í•¨ìˆ˜ ê°’ì˜ ë³€ë™ ì¶”ì´ ë˜í•œ ì˜ˆì¸¡ì˜ ì •í™•ë„ë§Œí¼ ì¤‘ìš”í•œ í‰ê°€ ìš”ì†Œë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, í•™ìŠµì„ ì§„í–‰í•  ë•Œ ë‘ ë°ì´í„°ì— ëŒ€í•œ ì†ì‹¤í•¨ìˆ˜ ê°’ì˜ ë³€ë™ê³¼ ì •í™•ë„ì˜ ë³€ë™ì„ í•­ìƒ ë³„ë„ì˜ listì— ì €ì¥í•´ë†“ëŠ” ì½”ë”© ìŠµê´€ì„ ë“¤ì—¬ë†“ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì‹œê°„ì„ ì¸¡ì •í•˜ëŠ” ìŠµê´€ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤!\n",
    "\n",
    "> EpochëŠ” ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ì¬í™œìš©í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•  ê²ƒì¸ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì´ epochê°€ 30ìœ¼ë¡œ ë˜ì–´ ìˆìœ¼ë©´, ì „ì²´ ë°ì´í„°ì…‹ì„ 30ë²ˆ ë°˜ë³µí•´ì„œ í•™ìŠµí•  ê²ƒì´ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤. \n",
    "\n",
    "> ì•„ë˜ì˜ í•™ìŠµ ì½”ë“œëŠ” ëª¨ë¸ì˜ ì¢…ë¥˜ì— ë”°ë¼ ì¡°ê¸ˆì€ ë°”ë€” ìˆ˜ ìˆê² ì§€ë§Œ, í° í‹€ì—ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ì€ ëŒ€ë¶€ë¶„ ì•„ë˜ì˜ ì½”ë“œì™€ ìœ ì‚¬í•œ í˜•íƒœì˜ ì½”ë“œë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì•„ë˜ ì½”ë“œë¥¼ ì˜ ìµí˜€ë‘ë©´ ì•ìœ¼ë¡œë„ í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë“œê°€ ë³µì¡í•˜ë¯€ë¡œ, í•œ ì¤„ í•œ ì¤„ ì´í•´í•˜ê³  ë„˜ì–´ê°€ê¸¸ ë°”ëë‹ˆë‹¤!\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2131989,
     "status": "ok",
     "timestamp": 1647071115005,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "moIzZ7vPMsrC",
    "outputId": "6a783227-71b4-487f-e062-a68c89c6b9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 49s (- 40m 42s) (2000 2%) 5.0202\n",
      "1m 30s (- 36m 3s) (4000 4%) 5.0114\n",
      "2m 15s (- 35m 26s) (6000 6%) 4.8920\n",
      "2m 57s (- 34m 1s) (8000 8%) 4.7364\n",
      "3m 38s (- 32m 50s) (10000 10%) 4.6394\n",
      "4m 20s (- 31m 49s) (12000 12%) 4.4759\n",
      "5m 1s (- 30m 52s) (14000 14%) 4.3749\n",
      "5m 43s (- 30m 0s) (16000 16%) 4.2596\n",
      "6m 24s (- 29m 11s) (18000 18%) 4.1226\n",
      "7m 5s (- 28m 21s) (20000 20%) 3.9746\n",
      "7m 46s (- 27m 35s) (22000 22%) 3.8735\n",
      "8m 27s (- 26m 48s) (24000 24%) 3.7415\n",
      "9m 9s (- 26m 3s) (26000 26%) 3.6211\n",
      "9m 50s (- 25m 19s) (28000 28%) 3.4939\n",
      "10m 32s (- 24m 36s) (30000 30%) 3.3449\n",
      "11m 14s (- 23m 52s) (32000 32%) 3.2235\n",
      "11m 55s (- 23m 8s) (34000 34%) 3.1012\n",
      "12m 37s (- 22m 26s) (36000 36%) 2.9879\n",
      "13m 19s (- 21m 44s) (38000 38%) 2.8256\n",
      "14m 1s (- 21m 2s) (40000 40%) 2.7176\n",
      "14m 46s (- 20m 24s) (42000 42%) 2.6389\n",
      "15m 28s (- 19m 41s) (44000 44%) 2.5138\n",
      "16m 12s (- 19m 1s) (46000 46%) 2.4492\n",
      "16m 57s (- 18m 22s) (48000 48%) 2.3232\n",
      "17m 41s (- 17m 41s) (50000 50%) 2.2427\n",
      "18m 23s (- 16m 58s) (52000 52%) 2.1067\n",
      "19m 5s (- 16m 16s) (54000 54%) 1.9761\n",
      "19m 48s (- 15m 33s) (56000 56%) 1.9044\n",
      "20m 30s (- 14m 51s) (58000 57%) 1.8171\n",
      "21m 12s (- 14m 8s) (60000 60%) 1.6682\n",
      "21m 55s (- 13m 26s) (62000 62%) 1.6406\n",
      "22m 37s (- 12m 43s) (64000 64%) 1.5355\n",
      "23m 20s (- 12m 1s) (66000 66%) 1.4808\n",
      "24m 3s (- 11m 19s) (68000 68%) 1.4084\n",
      "24m 45s (- 10m 36s) (70000 70%) 1.3360\n",
      "25m 29s (- 9m 54s) (72000 72%) 1.3070\n",
      "26m 12s (- 9m 12s) (74000 74%) 1.1935\n",
      "26m 54s (- 8m 29s) (76000 76%) 1.0969\n",
      "27m 37s (- 7m 47s) (78000 78%) 1.0576\n",
      "28m 20s (- 7m 5s) (80000 80%) 1.0394\n",
      "29m 3s (- 6m 22s) (82000 82%) 0.9584\n",
      "29m 45s (- 5m 40s) (84000 84%) 0.9052\n",
      "30m 28s (- 4m 57s) (86000 86%) 0.8681\n",
      "31m 11s (- 4m 15s) (88000 88%) 0.8691\n",
      "31m 54s (- 3m 32s) (90000 90%) 0.7746\n",
      "32m 38s (- 2m 50s) (92000 92%) 0.7237\n",
      "33m 22s (- 2m 7s) (94000 94%) 0.6782\n",
      "34m 6s (- 1m 25s) (96000 96%) 0.6425\n",
      "34m 48s (- 0m 42s) (98000 98%) 0.6175\n",
      "35m 31s (- 0m 0s) (100000 100%) 0.5754\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 100000, print_every=2000)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWApo0KmlWvR"
   },
   "source": [
    "### **4-3) ê²°ê³¼ ì‹œê°í™”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz-pG0tPHpqh"
   },
   "source": [
    "---\n",
    "> Tensorboardë¥¼ ì‚¬ìš©í•˜ì—¬ Lossì˜ ë³€í™” ê³¼ì •ì„ ì¶”ì í•´ë³´ê² ìŠµë‹ˆë‹¤. Tensorboardê°€ ì¼ë°˜ plotë“¤ë³´ë‹¤ ì¢‹ì€ ì´ìœ ëŠ”, ì‚¬ìš©ìê°€ ê·¸ë˜í”„ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. Tensorboardì—ëŠ” Lossë‚˜ Accuracy ì‹œê°í™” ì´ì™¸ì—ë„ ì •ë§ ë‹¤ì–‘í•œ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì´ ìˆìœ¼ë¯€ë¡œ, í•œ ë²ˆ ì°¾ì•„ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkwaNlQRH5n1"
   },
   "outputs": [],
   "source": [
    "# Tensorboard ì‚¬ìš© í™˜ê²½ ì¤€ë¹„\n",
    "\n",
    "! pip install jupyter-tensorboard\n",
    "! docker pull lspvic/tensorboard-notebook\n",
    "! docker run -it --rm -p 8888:8888 lspvic/tensorboard-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mf1dASROIBWN"
   },
   "outputs": [],
   "source": [
    "# tfevent íŒŒì¼ tensorboardì—ì„œ í™•ì¸\n",
    " # í•œ ë²ˆ ë” í™•ì¸í•  ë•ŒëŠ” reload_ext\n",
    "\n",
    "%load_ext tensorboard \n",
    "%tensorboard --logdir ./runs/Mar12_06-49-04_fa77f294e477 # tfevent íŒŒì¼ì´ ìœ„ì¹˜í•˜ê³  ìˆëŠ” ë””ë ‰í† ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG5nt2Zxoixl"
   },
   "source": [
    "### **4-4) Attention ì‹œê°í™”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGEGCEkA9M-0"
   },
   "source": [
    "---\n",
    "> ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê°€ì¥ í° ë‹¨ì ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê²ƒì´ ë°”ë¡œ ë”¥ëŸ¬ë‹ì€ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ì´ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì´ ì–´ë–»ê²Œ ì§„í–‰ë˜ì—ˆëŠ”ì§€ ì„¤ëª…í• ìˆ˜ê°€ ì—†ë‹¤ëŠ” ì ì¸ë°ìš”, ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‚˜ì˜¨ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ë°”ë¡œ ì„¤ëª… ê°€ëŠ¥í•œ ì¸ê³µì§€ëŠ¥(XAI) ì…ë‹ˆë‹¤. Attention ê¸°ë²•ì€ ì¶œë ¥ì´ ì…ë ¥ì˜ ì–´ë–¤ ë¶€ë¶„ì„ íŠ¹íˆ ì§‘ì¤‘í•´ì„œ ë³´ì•„ì•¼ í• ì§€ ê²°ì •í•´ì¤€ë‹¤ëŠ” ì ì—ì„œ XAI ê¸°ë²•ì˜ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "> ë”°ë¼ì„œ, ì„ì˜ì˜ ì˜ì–´ ë¬¸ì¥ì„ ë„£ì–´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­ì´ ì§„í–‰ë  ë•Œ ì •í™•íˆ ì…ë ¥ ë¬¸ì¥ì˜ ì–´ë–¤ ë¶€ë¶„ì— ì§‘ì¤‘í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzH5A_xGXJoj"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1647071281020,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "TS0Szk9_iKH3",
    "outputId": "457e21e1-9247-4d96-9f1d-614703acf446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë²ˆì—­ ë¬¸ì¥:  ì¼ë³¸ì—ëŠ” í­ê·„ì„ í‚¤ìš°ëŠ” ì‚¬ëŒì´ ìˆëŒ€ . <EOS>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6f005c510>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 822.857x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attention Value í™•ì¸\n",
    "\n",
    "output_words, attentions = evaluate(encoder1, attn_decoder1, \"I hear that there are people in Japan that keep penguins as pets .\")\n",
    "print(\"ë²ˆì—­ ë¬¸ì¥: \", ' '.join(output_words))\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KrtbbKOHk-g"
   },
   "source": [
    "### **4-5) ê²°ê³¼ í™•ì¸**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAuFnMJuXPdG"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647071116156,
     "user": {
      "displayName": "í™ì§€ìš°",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "xIBeHi-1XZJ-",
    "outputId": "22d19f77-2fe9-41eb-ddd8-d22ea11bfcfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Lack of sleep is bad for the body .\n",
      "= ìˆ˜ë©´ ë¶€ì¡±ì€ ëª¸ì— ë‚˜ë¹  .\n",
      "< ìˆ˜ë©´ ë¶€ì¡±ì€ ëª¸ì— ë‚˜ë¹  . <EOS>\n",
      "\n",
      "> Do you believe this has any use ?\n",
      "= ì´ê²Œ ì“¸ëª¨ê°€ ìˆì„ê±°ë¼ê³  ìƒê°í•´ ?\n",
      "< ì´ê²Œ ì“¸ëª¨ê°€ ìˆì„ê±°ë¼ê³  ìƒê°í•´ ? <EOS>\n",
      "\n",
      "> All of us have some interest in history . In a sense, we are all historians .\n",
      "= ìš°ë¦¬ ë‹¤ ì—­ì‚¬ì— ê´€ì‹¬ì´ ìˆì–´ì„œ ì–´ë–¤ ì˜ë¯¸ë¡œ ìš°ë¦¬ëŠ” ëª¨ë‘ ì—­ì‚¬ê°€ë‹¤ .\n",
      "< ìš°ë¦¬ ë‹¤ ì—­ì‚¬ì— ì–´ë–¤ ì–´ë–¤ ì°¾ì„ ìˆ˜ ì˜ë¯¸ë¡œ ìš°ë¦¬ëŠ” ëª¨ë‘ . <EOS>\n",
      "\n",
      "> The earth is far bigger than the moon .\n",
      "= ì§€êµ¬ëŠ” ë‹¬ë³´ë‹¤ í›¨ì”¬ ì»¤ .\n",
      "< ì§€êµ¬ëŠ” ë‹¬ë³´ë‹¤ í›¨ì”¬ ì»¤ . <EOS>\n",
      "\n",
      "> Nobody died .\n",
      "= ì•„ë¬´ë„ ì£½ì§€ ì•Šì•˜ì–´ .\n",
      "< ì•„ë¬´ë„ ì•ˆ ì£½ì—ˆì–´ . <EOS>\n",
      "\n",
      "> You can learn French .\n",
      "= ë„Œ í”„ë‘ìŠ¤ì–´ë¥¼ ë°°ìš¸ ìˆ˜ ìˆì–´ .\n",
      "< ë„Œ í”„ë‘ìŠ¤ì–´ë¥¼ ë°°ìš¸ ìˆ˜ ìˆì–´ . <EOS>\n",
      "\n",
      "> I envy you .\n",
      "= ë„¤ê°€ ë¶€ëŸ¬ì›Œ .\n",
      "< ë„¤ê°€ ë¶€ëŸ¬ì›Œ . <EOS>\n",
      "\n",
      "> You'll soon get used to the noise .\n",
      "= ë„Œ ê³§ ì†ŒìŒì— ìµìˆ™í•´ì§ˆê±°ì•¼ .\n",
      "< ë„Œ ê³§ ì†ŒìŒì— ìµìˆ™í•´ì§ˆê±°ì•¼ . <EOS>\n",
      "\n",
      "> Would you mind answering a few questions ?\n",
      "= ëª‡ ê°€ì§€ ì§ˆë¬¸ì— ë‹µí•  ì˜í–¥ ìˆì–´ ?\n",
      "< ëª‡ ëª‡ ì§ˆë¬¸ì— ë‹µí•  ìˆë‹ˆ ? <EOS>\n",
      "\n",
      "> How many of the people here are teachers ?\n",
      "= ì—¬ê¸°ì— ìˆëŠ” ì‚¬ëŒ ì¤‘ ëª‡ëª…ì´ ì„ ìƒë‹˜ì´ì•¼ ?\n",
      "< ì—¬ê¸°ì— ìˆëŠ” ì‚¬ëŒ ì¤‘ ëª‡ëª…ì´ ì„ ìƒë‹˜ì´ì•¼ ? <EOS>\n",
      "\n",
      "> Step back .\n",
      "= ë¬¼ëŸ¬ì„œ .\n",
      "< ë¬¼ëŸ¬ì„œ . <EOS>\n",
      "\n",
      "> Oh no !\n",
      "= ì•„ë‹ˆ ì´ëŸ° !\n",
      "< ì•„ë‹ˆ ì´ëŸ° ! <EOS>\n",
      "\n",
      "> He came out of the shower naked .\n",
      "= ê·¸ëŠ” ì•Œëª¸ìœ¼ë¡œ ìƒ¤ì›Œì‹¤ì—ì„œ ë‚˜ì™”ë‹¤ .\n",
      "< ê·¸ëŠ” ì•Œëª¸ìœ¼ë¡œ ìƒ¤ì›Œì‹¤ì—ì„œ ë‚˜ì™”ë‹¤ . <EOS>\n",
      "\n",
      "> Tom knows that we can't do that .\n",
      "= í†°ì€ ìš°ë¦¬ê°€ ì €ê±´ í•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì„ ì•Œê³  ìˆì–´ .\n",
      "< í†°ì€ ìš°ë¦¬ê°€ ì €ê±´ í•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì„ ì•Œê³  ìˆì–´ . <EOS>\n",
      "\n",
      "> You should try this . It's delicious .\n",
      "= ë„ˆ ì´ê±° í•œë²ˆ ë§›ë´ì•¼í•´ . ì´ê±° ë§›ìˆê±°ë“  .\n",
      "< ë„ˆ ì´ê±° í•œë²ˆ ë§›ë´ì•¼í•´ . ì´ê±° . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1, n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnKN_78Xnd-Y"
   },
   "source": [
    "## **5. ë§ˆë¬´ë¦¬**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFhPGTe7nmtP"
   },
   "source": [
    "---\n",
    "> ì§€ê¸ˆê¹Œì§€ NLPì˜ ëŒ€í‘œì  ê³¼ì œ ì¤‘ í•˜ë‚˜ì¸ ê¸°ê³„ë²ˆì—­ì„ Seq2Seqì™€ Attention ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ìˆ˜í–‰í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì €ë„ ê°œì¸ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ì²˜ë¦¬ë¥¼ í•´ë³¸ ì ì´ ì—†ì–´ì„œ Pytorchì˜ íŠœí† ë¦¬ì–¼ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìŠµ ë‚´ìš©ì„ êµ¬ì„±í•˜ë©° ë§ì€ ê³µë¶€ê°€ ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë°ì´í„°ì˜ í¬ê¸°ê°€ ë§¤ìš° ì‘ë‹¤ëŠ” ì , ê·¸ë¦¬ê³  ê°€ì¥ ê°„ë‹¨í•œ êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆë‹¤ëŠ” ì ì—ì„œ ì‹¤ì œ ëŒ€í™”ì—ì„œ ì˜¤ê°€ëŠ” í‘œí˜„ì„ ë²ˆì—­í•˜ëŠ” ê²ƒì—ëŠ” ë¬´ë¦¬ê°€ ìˆì„ ê²ƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ, Encoder-Decoderê°€ ì–´ë–»ê²Œ êµ¬í˜„ë˜ëŠ”ì§€, RNN ê²Œì—´ì˜ ëª¨ë¸ì€ pytorchì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ ë¶€ë¶„ë„ 2ì£¼ì°¨ ì‹¤ìŠµê³¼ ë”ë¶ˆì–´ í•œ ì¤„ í•œ ì¤„ ë³µìŠµí•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4UvSrkEnh6z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
