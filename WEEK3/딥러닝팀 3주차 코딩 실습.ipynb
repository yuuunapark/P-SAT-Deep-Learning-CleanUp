{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9LFysohORkY"
   },
   "source": [
    "# **딥러닝팀 클린업 3주차 코딩 실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaZb2cWGgT4Z"
   },
   "source": [
    "> 🖥**Produced by 김예찬 (feat. 지멘, 구글링)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SeAlcg8Oai0"
   },
   "source": [
    "---\n",
    "> 3주차에는 자연어처리(NLP) 분야의 딥러닝 모델을 학습해볼 예정입니다. \n",
    "\n",
    "> NLP에서는 RNN을 기반으로 하는 모델들이 주로 사용되므로, 오늘은 Attention 기법을 적용한 Seq2Seq 모델을 활용하여 영어와 한국어 간의 기계번역 과제를 수행해볼 예정입니다.\n",
    "\n",
    "> 더불어, 딥러닝 모델을 학습할 때는 물론, 강화학습 알고리즘을 학습할 때도 사용가능한 Tensorboard라는 것을 사용해볼 것입니다. Tensorboard는 모델의 학습 과정에서 loss나 정확도, 파라미터의 값 등을 추적할 수 있도록 도와주는 기능이며, tensorflow라는 딥러닝 프레임워크의 기능이지만 pytorch에서도 사용이 가능합니다.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTnGF5KTTvgo"
   },
   "source": [
    "### **0-1) Drive Mount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21348,
     "status": "ok",
     "timestamp": 1647422860633,
     "user": {
      "displayName": "김예찬",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06067702609339936211"
     },
     "user_tz": -540
    },
    "id": "5IKSpK32UrHF",
    "outputId": "40244801-eb8f-4ba8-8788-90c517cac126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Drive Mount\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Working Directory 변경\n",
    "\n",
    "import os\n",
    "\n",
    "directory = \"\" # 파일이 있는 디렉토리\n",
    "path = \"/content/gdrive/My Drive/\" + directory\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlnDSgf1ZJax"
   },
   "source": [
    "### **0-2) 한글 깨짐 현상**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17445,
     "status": "ok",
     "timestamp": 1647422884122,
     "user": {
      "displayName": "김예찬",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06067702609339936211"
     },
     "user_tz": -540
    },
    "id": "8PV5BA5sZJt5",
    "outputId": "0d32a898-7f6a-438f-b989-d7ea47d09978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package fonts-nanum.\n",
      "(Reading database ... 155335 files and directories currently installed.)\n",
      "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
      "Unpacking fonts-nanum (20170925-1) ...\n",
      "Selecting previously unselected package fonts-nanum-eco.\n",
      "Preparing to unpack .../fonts-nanum-eco_1.000-6_all.deb ...\n",
      "Unpacking fonts-nanum-eco (1.000-6) ...\n",
      "Selecting previously unselected package fonts-nanum-extra.\n",
      "Preparing to unpack .../fonts-nanum-extra_20170925-1_all.deb ...\n",
      "Unpacking fonts-nanum-extra (20170925-1) ...\n",
      "Selecting previously unselected package fonts-nanum-coding.\n",
      "Preparing to unpack .../fonts-nanum-coding_2.5-1_all.deb ...\n",
      "Unpacking fonts-nanum-coding (2.5-1) ...\n",
      "Setting up fonts-nanum-extra (20170925-1) ...\n",
      "Setting up fonts-nanum (20170925-1) ...\n",
      "Setting up fonts-nanum-coding (2.5-1) ...\n",
      "Setting up fonts-nanum-eco (1.000-6) ...\n",
      "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
      "NanumBarunGothic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install fonts-nanum* -qq\n",
    "\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "fm._rebuild()\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "font = fm.FontProperties(fname=path, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwbnvbJgvQ5H"
   },
   "source": [
    "### **0-3) 시드 고정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-q3_AUZvTMx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed: int = 824):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "random_state = 824\n",
    "seed_everything(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPwaoPTKWEoy"
   },
   "source": [
    "## **1. 데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZFkaDSgWJwV"
   },
   "source": [
    "---\n",
    "> 영어와 한국어의 조합으로 이루어진 eng_to_kor.txt 텍스트 데이터를 불러오고, 텍스트 데이터를 숫자 데이터로 바꿔주는 class를 구현하여 Seq2Seq에 대입할 수 있는 입력 데이터를 준비해볼 것입니다. \n",
    "\n",
    "> 3주차 클린업에서 배운 임베딩(Embedding) 등을 떠올려 봅시다!\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p89TDpMkUQ4k"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzJFqr2TarOG"
   },
   "source": [
    "### **1-1) 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "855AUoTBa4DL"
   },
   "source": [
    "---\n",
    "> 오늘 만들어볼 기계번역 모델은 영어를 한국어로 번역하는 것을 목적으로 합니다. 데이터에 어떤 문장들이 있는지 한 번 확인해보도록 하겠습니다.\n",
    "\n",
    "> 아래의 15개 문장은 매우 짧지만, 해당 .txt 파일에는 이렇게 짧은 문장부터 긴 문장까지 여러가지 문장들이 포함되어 있습니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3Ywi6SwbqF9"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "data = open(\"./test/PSAT/3주차 코딩실습/eng_to_kor.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1647067047548,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "Ux2mLn2Qavs_",
    "outputId": "afe0669c-3164-49a7-ab24-20ddd2d4a75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\t가.\n",
      "\n",
      "Hi.\t안녕.\n",
      "\n",
      "Run!\t뛰어!\n",
      "\n",
      "Run.\t뛰어.\n",
      "\n",
      "Who?\t누구?\n",
      "\n",
      "Wow!\t우와!\n",
      "\n",
      "Fire!\t쏴!\n",
      "\n",
      "Help!\t도와줘!\n",
      "\n",
      "Jump!\t점프!\n",
      "\n",
      "Jump.\t점프해.\n",
      "\n",
      "Wait!\t기다려!\n",
      "\n",
      "Wait!\t잠깐!\n",
      "\n",
      "Wait.\t기다려.\n",
      "\n",
      "Begin.\t시작해.\n",
      "\n",
      "Hello!\t안녕!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "for i in range(15):\n",
    "    print(data.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvD9eRrrcJ-p"
   },
   "source": [
    "### **1-2) Word Indexing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxOyp_lzcMpt"
   },
   "source": [
    "---\n",
    "> Seq2Seq는 RNN을 베이스로 하는 Encoder-Decoder 구조이기 때문에 순차적으로 입력이 들어가게 됩니다. 따라서 우리의 텍스트 데이터에 순차적으로 번호를 붙여줄 예정인데, 이를 Word Indexing이라고 합니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AE5g2fIdcuAz"
   },
   "outputs": [],
   "source": [
    "# Word Indexing을 위한 class 구현\n",
    "\n",
    "SOS_token = 0 # Start of Sentence 토큰 (Decoder의 첫 입력)\n",
    "EOS_token = 1 # End of Sentence 토큰 (Decoder의 마지막 출력)\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    # __init__ 함수는 이 class의 객체가 처음 정의되는 순간 아래의 dictionary들이 자동으로 생성됨을 의미합니다.\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS 와 EOS 포함\n",
    "\n",
    "    # 문장을 입력받아 띄어쓰기 단위로 끊고, 여기서 얻은 단어들을 dictionary에 저장합니다.\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    # 문장 속에 있는 단어들을 dictionary에 저장하는 동시에 단어의 빈도수를 카운트합니다.\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSC0C_uFc-Pg"
   },
   "source": [
    "### **1-3) 데이터 정제**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFnd87_IdEYQ"
   },
   "source": [
    "---\n",
    "> 3주타 클린업에서 배웠듯이, 자연어를 전처리할 때는 의미를 해석하는 것에 도움이 되지 않는 요소들을 최대한 제거합니다. 예를 들면, 고유명사 등을 제외한 단어들은 소문자/대문자 여부가 의미에 영향을 끼치지 않기 때문에, 제거해줍니다.\n",
    "\n",
    "> 지금은 간단한 번역 모델만 구현하는 것이므로, 구두점만 제거해주도록 하겠습니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgczcqGGd7MM"
   },
   "outputs": [],
   "source": [
    "# 문자가 아닌 문자 제거 (의미에 영향을 주지 않는 요소들 제거)\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTXKaeUsj2js"
   },
   "source": [
    "### **1-4) 데이터 분리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfDg311Oj66R"
   },
   "source": [
    "---\n",
    "> 여기서 말하는 데이터 분리란, 영어와 한국어 데이터가 모두 들어있는 .txt 데이터를 영어 데이터셋과 한국어 데이터셋으로 분리하는 것을 의미합니다. 한 마디로, (X, y) 형태로 분리하는 것과 동일합니다.\n",
    "\n",
    "> 학습의 편의를 위해 종료 부호를 포함하여 총 20단어 이내의 문장에 대해서만 학습을 진행하도록 하겠습니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cji6aQLwjbgW"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터와 타겟 데이터 분리\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # 파일을 읽고 줄로 분리\n",
    "    lines = open('./test/PSAT/3주차 코딩실습/%s_to_%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # 모든 줄을 쌍으로 분리하고 정규화(구두점 제거)\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # 쌍을 뒤집고, Lang 인스턴스 생성\n",
    "    if reverse: \n",
    "        pairs = [list(reversed(p)) for p in pairs]    # 현재 모델은 영어 --> 한국어이지만, reverse를 적용하면 한국어 --> 영어가 됩니다!\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9Ty02XCRs7Q"
   },
   "outputs": [],
   "source": [
    "# 영어와 한국어 모두 20 단어 이내로 설정\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC7uKT3fsQWs"
   },
   "source": [
    "### **1-5) DataLoader 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOkozla-sWcH"
   },
   "source": [
    "---\n",
    "> 앞서 만든 class들과 함수들을 바탕으로 최종적으로 데이터를 반환해주는 Loader를 구현합니다. 구체적으로 다음의 절차에 따라 우리가 모델에 사용할 데이터들을 전달합니다.\n",
    "\n",
    "1.   텍스트 파일을 읽어들인 후 줄로 분리하며, 영어와 한국어의 쌍으로 분리합니다. \n",
    "2.   텍스트를 정제하고, 길이가 20 단어가 넘는 문장들을 제거합니다.\n",
    "3.   (영어, 한국어)의 상을 이룬 문장들을 바탕으로 단어의 리스트를 생성합니다.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1647067064803,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "peZY_Vd9TJvs",
    "outputId": "d53718bc-bd0f-4630-9b4e-cefb3cda1e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 3798 sentence pairs\n",
      "Trimmed to 3792 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2986\n",
      "kor 5737\n",
      "[\"Let's hear the rest of the story .\", '이야기를 마저 들어 봅시다 .']\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터의 형식에 맞게 데이터 반환\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'kor', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MU1XtMLQWNlH"
   },
   "outputs": [],
   "source": [
    "# 입출력 데이터 모두 tensor로 변환 + sos & eos 토큰 넣기\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym3xQ41HuY-H"
   },
   "source": [
    "## **3. 모델링**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MpsUd8Sub6P"
   },
   "source": [
    "---\n",
    "> 이제 모델을 만들어보겠습니다! 저번주와 마찬가지로 Pytorch를 사용하여 모델을 구현할 예정이며, Encoder-Decoder 구조를 기반으로 하는 Seq2Seq 모델에 Attention 기법을 추가할 예정입니다. 따라서, 크게 Encoder, Decoder 2가지 모델을 만든 후 이 2가지 모델을 병합하는 방식으로 최종 모델을 구현할 것입니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwNj0q-evA1m"
   },
   "source": [
    "### **3-1) 모델 정의**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCBPpnVfvPYV"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "1. Encoder: 영어 입력 문장들을 임베딩한 후 GRU 유닛으로 통과시킵니다. \n",
    "   * 영어 입력 문장들을 임베딩(벡터의 형태로 표현)\n",
    "   * GRU 유닛을 통과시켜 Hidden State 연산\n",
    "   * Hidden State를 출력으로 반환\n",
    "\n",
    "\n",
    "2. Decoder: Encoder의 마지막 Hidden State와 한국어를 입력으로 받아 번역\n",
    "   * 한국어 입력 문장들을 임베딩\n",
    "   * GRU 유닛을 통과시켜 Hidden State와 Output 연산\n",
    "   * 매 시점 Output을 차례로 FC Layer, Softmax에 통과시켜 나올 수 있는 번역된 단어 반환\n",
    "\n",
    "\n",
    "3. Attention Decoder: Decoder와 구조는 동일하지만 Attention 기법 적용\n",
    "   * 클린업에서 배운 Dot Product Attention 기법 대신 FC Layer를 사용하여 Attention Score를 계산하는 방법 적용\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02kV44HKvAUW"
   },
   "outputs": [],
   "source": [
    "# Encoder 정의\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)  # device는 2주차 실습에서 별도로 .to('cuda')를 모델 내에서 미리 하는 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SH2prlspPO9l"
   },
   "outputs": [],
   "source": [
    "# Decoder 정의 - Seq2Seq\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6mUhzHbPdTo"
   },
   "outputs": [],
   "source": [
    "# Attention Decoder 정의\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647067159521,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "tfvJhW6i2jb0",
    "outputId": "ba083659-7acc-4cf8-a693-46fca62dbda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(20, 128)\n",
      "  (gru): GRU(128, 128)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(EncoderRNN(20, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m-QG0Luygd8"
   },
   "source": [
    "### **3-2) 모델 개요 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1647067564070,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "uDZv7V17j8D7",
    "outputId": "b4f0f650-9ee3-49fb-e47a-82a0eb326c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "EncoderRNN                               --\n",
       "├─Embedding: 1-1                         2,560\n",
       "├─GRU: 1-2                               99,072\n",
       "=================================================================\n",
       "Total params: 101,632\n",
       "Trainable params: 101,632\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(EncoderRNN(20, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1647067605284,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "eoowh7Bp4JzX",
    "outputId": "38af27e0-85b9-45b4-baa3-b737a59883ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "DecoderRNN                               --\n",
       "├─Embedding: 1-1                         2,560\n",
       "├─GRU: 1-2                               99,072\n",
       "├─Linear: 1-3                            2,580\n",
       "├─LogSoftmax: 1-4                        --\n",
       "=================================================================\n",
       "Total params: 104,212\n",
       "Trainable params: 104,212\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(DecoderRNN(128, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647067625322,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "zHhxfM7i4MUJ",
    "outputId": "7b85c634-a874-4a51-e48c-4afedd189e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "AttnDecoderRNN                           --\n",
       "├─Embedding: 1-1                         2,560\n",
       "├─Linear: 1-2                            5,140\n",
       "├─Linear: 1-3                            32,896\n",
       "├─Dropout: 1-4                           --\n",
       "├─GRU: 1-5                               99,072\n",
       "├─Linear: 1-6                            2,580\n",
       "=================================================================\n",
       "Total params: 142,248\n",
       "Trainable params: 142,248\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(AttnDecoderRNN(128, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6SKAGhYDuzx"
   },
   "source": [
    "## **4. 학습 및 평가**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6Be4DgdD6MH"
   },
   "source": [
    "### **4-1) 모델 학습 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2310nWuPm4Yr"
   },
   "outputs": [],
   "source": [
    "# train 함수 정의 - 교사강요 포함!\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuHh07UDZR2j"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# 결과 시각화\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiCr0evwWjhJ"
   },
   "outputs": [],
   "source": [
    "# 학습 시간 및 소요 시간 계산\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNwm1IUP4xDL"
   },
   "outputs": [],
   "source": [
    "# Tensorboard 사용 준비\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB3tdkytW3O0"
   },
   "outputs": [],
   "source": [
    "# 전체 학습 Flow 완성!\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every 마다 초기화\n",
    "    plot_loss_total = 0   # plot_every 마다 초기화\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) # Encoder의 Optim\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) # Decoder의 Optim\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        writer.add_scalar(\"Loss\", loss, iter)                            # Encoder의 loss 저장\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDN6nXV3MngM"
   },
   "source": [
    "### **4-2) 모델 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "griSjxndOXCV"
   },
   "source": [
    "-----\n",
    "> 본격적으로 모델 학습을 시작해보겠습니다. 1주차에서 살펴본 바와 같이, 딥러닝에서 학습은 보통 손실함수의 값을 최소화시키는 과정을 따라 이루어지며, 그 과정에서 학습 데이터 및 검증 데이터에 대한 예측의 정확도가 올라가게 됩니다. 때문에, 손실함수 값의 변동 추이 또한 예측의 정확도만큼 중요한 평가 요소라고 할 수 있습니다. 따라서, 학습을 진행할 때 두 데이터에 대한 손실함수 값의 변동과 정확도의 변동을 항상 별도의 list에 저장해놓는 코딩 습관을 들여놓는 것이 좋습니다. 시간을 측정하는 습관도 마찬가지입니다!\n",
    "\n",
    "> Epoch는 전체 데이터셋을 몇 번 재활용하여 학습을 진행할 것인지를 의미합니다. 아래와 같이 epoch가 30으로 되어 있으면, 전체 데이터셋을 30번 반복해서 학습할 것이라는 뜻입니다. \n",
    "\n",
    "> 아래의 학습 코드는 모델의 종류에 따라 조금은 바뀔 수 있겠지만, 큰 틀에서 딥러닝 모델들은 대부분 아래의 코드와 유사한 형태의 코드로 학습을 진행합니다. 따라서, 아래 코드를 잘 익혀두면 앞으로도 편하게 사용할 수 있습니다. 코드가 복잡하므로, 한 줄 한 줄 이해하고 넘어가길 바랍니다!\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2131989,
     "status": "ok",
     "timestamp": 1647071115005,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "moIzZ7vPMsrC",
    "outputId": "6a783227-71b4-487f-e062-a68c89c6b9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 49s (- 40m 42s) (2000 2%) 5.0202\n",
      "1m 30s (- 36m 3s) (4000 4%) 5.0114\n",
      "2m 15s (- 35m 26s) (6000 6%) 4.8920\n",
      "2m 57s (- 34m 1s) (8000 8%) 4.7364\n",
      "3m 38s (- 32m 50s) (10000 10%) 4.6394\n",
      "4m 20s (- 31m 49s) (12000 12%) 4.4759\n",
      "5m 1s (- 30m 52s) (14000 14%) 4.3749\n",
      "5m 43s (- 30m 0s) (16000 16%) 4.2596\n",
      "6m 24s (- 29m 11s) (18000 18%) 4.1226\n",
      "7m 5s (- 28m 21s) (20000 20%) 3.9746\n",
      "7m 46s (- 27m 35s) (22000 22%) 3.8735\n",
      "8m 27s (- 26m 48s) (24000 24%) 3.7415\n",
      "9m 9s (- 26m 3s) (26000 26%) 3.6211\n",
      "9m 50s (- 25m 19s) (28000 28%) 3.4939\n",
      "10m 32s (- 24m 36s) (30000 30%) 3.3449\n",
      "11m 14s (- 23m 52s) (32000 32%) 3.2235\n",
      "11m 55s (- 23m 8s) (34000 34%) 3.1012\n",
      "12m 37s (- 22m 26s) (36000 36%) 2.9879\n",
      "13m 19s (- 21m 44s) (38000 38%) 2.8256\n",
      "14m 1s (- 21m 2s) (40000 40%) 2.7176\n",
      "14m 46s (- 20m 24s) (42000 42%) 2.6389\n",
      "15m 28s (- 19m 41s) (44000 44%) 2.5138\n",
      "16m 12s (- 19m 1s) (46000 46%) 2.4492\n",
      "16m 57s (- 18m 22s) (48000 48%) 2.3232\n",
      "17m 41s (- 17m 41s) (50000 50%) 2.2427\n",
      "18m 23s (- 16m 58s) (52000 52%) 2.1067\n",
      "19m 5s (- 16m 16s) (54000 54%) 1.9761\n",
      "19m 48s (- 15m 33s) (56000 56%) 1.9044\n",
      "20m 30s (- 14m 51s) (58000 57%) 1.8171\n",
      "21m 12s (- 14m 8s) (60000 60%) 1.6682\n",
      "21m 55s (- 13m 26s) (62000 62%) 1.6406\n",
      "22m 37s (- 12m 43s) (64000 64%) 1.5355\n",
      "23m 20s (- 12m 1s) (66000 66%) 1.4808\n",
      "24m 3s (- 11m 19s) (68000 68%) 1.4084\n",
      "24m 45s (- 10m 36s) (70000 70%) 1.3360\n",
      "25m 29s (- 9m 54s) (72000 72%) 1.3070\n",
      "26m 12s (- 9m 12s) (74000 74%) 1.1935\n",
      "26m 54s (- 8m 29s) (76000 76%) 1.0969\n",
      "27m 37s (- 7m 47s) (78000 78%) 1.0576\n",
      "28m 20s (- 7m 5s) (80000 80%) 1.0394\n",
      "29m 3s (- 6m 22s) (82000 82%) 0.9584\n",
      "29m 45s (- 5m 40s) (84000 84%) 0.9052\n",
      "30m 28s (- 4m 57s) (86000 86%) 0.8681\n",
      "31m 11s (- 4m 15s) (88000 88%) 0.8691\n",
      "31m 54s (- 3m 32s) (90000 90%) 0.7746\n",
      "32m 38s (- 2m 50s) (92000 92%) 0.7237\n",
      "33m 22s (- 2m 7s) (94000 94%) 0.6782\n",
      "34m 6s (- 1m 25s) (96000 96%) 0.6425\n",
      "34m 48s (- 0m 42s) (98000 98%) 0.6175\n",
      "35m 31s (- 0m 0s) (100000 100%) 0.5754\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 100000, print_every=2000)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWApo0KmlWvR"
   },
   "source": [
    "### **4-3) 결과 시각화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz-pG0tPHpqh"
   },
   "source": [
    "---\n",
    "> Tensorboard를 사용하여 Loss의 변화 과정을 추적해보겠습니다. Tensorboard가 일반 plot들보다 좋은 이유는, 사용자가 그래프와 상호작용하는 것이 가능하기 때문입니다. Tensorboard에는 Loss나 Accuracy 시각화 이외에도 정말 다양한 가능한 기능이 있으므로, 한 번 찾아보시기 바랍니다!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkwaNlQRH5n1"
   },
   "outputs": [],
   "source": [
    "# Tensorboard 사용 환경 준비\n",
    "\n",
    "! pip install jupyter-tensorboard\n",
    "! docker pull lspvic/tensorboard-notebook\n",
    "! docker run -it --rm -p 8888:8888 lspvic/tensorboard-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mf1dASROIBWN"
   },
   "outputs": [],
   "source": [
    "# tfevent 파일 tensorboard에서 확인\n",
    " # 한 번 더 확인할 때는 reload_ext\n",
    "\n",
    "%load_ext tensorboard \n",
    "%tensorboard --logdir ./runs/Mar12_06-49-04_fa77f294e477 # tfevent 파일이 위치하고 있는 디렉토리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG5nt2Zxoixl"
   },
   "source": [
    "### **4-4) Attention 시각화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGEGCEkA9M-0"
   },
   "source": [
    "---\n",
    "> 딥러닝 모델의 가장 큰 단점이라고 불리는 것이 바로 딥러닝은 블랙박스 모델이라는 것입니다. 딥러닝이 어떻게 진행되었는지 설명할수가 없다는 점인데요, 이를 극복하기 위해 나온 인공지능 모델이 바로 설명 가능한 인공지능(XAI) 입니다. Attention 기법은 출력이 입력의 어떤 부분을 특히 집중해서 보아야 할지 결정해준다는 점에서 XAI 기법의 하나입니다.\n",
    "\n",
    "> 따라서, 임의의 영어 문장을 넣어 한국어 문장으로 번역이 진행될 때 정확히 입력 문장의 어떤 부분에 집중하는지 확인해보도록 하겠습니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzH5A_xGXJoj"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1647071281020,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "TS0Szk9_iKH3",
    "outputId": "457e21e1-9247-4d96-9f1d-614703acf446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역 문장:  일본에는 펭귄을 키우는 사람이 있대 . <EOS>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6f005c510>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 822.857x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attention Value 확인\n",
    "\n",
    "output_words, attentions = evaluate(encoder1, attn_decoder1, \"I hear that there are people in Japan that keep penguins as pets .\")\n",
    "print(\"번역 문장: \", ' '.join(output_words))\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KrtbbKOHk-g"
   },
   "source": [
    "### **4-5) 결과 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAuFnMJuXPdG"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647071116156,
     "user": {
      "displayName": "홍지우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09687386104869736535"
     },
     "user_tz": -540
    },
    "id": "xIBeHi-1XZJ-",
    "outputId": "22d19f77-2fe9-41eb-ddd8-d22ea11bfcfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Lack of sleep is bad for the body .\n",
      "= 수면 부족은 몸에 나빠 .\n",
      "< 수면 부족은 몸에 나빠 . <EOS>\n",
      "\n",
      "> Do you believe this has any use ?\n",
      "= 이게 쓸모가 있을거라고 생각해 ?\n",
      "< 이게 쓸모가 있을거라고 생각해 ? <EOS>\n",
      "\n",
      "> All of us have some interest in history . In a sense, we are all historians .\n",
      "= 우리 다 역사에 관심이 있어서 어떤 의미로 우리는 모두 역사가다 .\n",
      "< 우리 다 역사에 어떤 어떤 찾을 수 의미로 우리는 모두 . <EOS>\n",
      "\n",
      "> The earth is far bigger than the moon .\n",
      "= 지구는 달보다 훨씬 커 .\n",
      "< 지구는 달보다 훨씬 커 . <EOS>\n",
      "\n",
      "> Nobody died .\n",
      "= 아무도 죽지 않았어 .\n",
      "< 아무도 안 죽었어 . <EOS>\n",
      "\n",
      "> You can learn French .\n",
      "= 넌 프랑스어를 배울 수 있어 .\n",
      "< 넌 프랑스어를 배울 수 있어 . <EOS>\n",
      "\n",
      "> I envy you .\n",
      "= 네가 부러워 .\n",
      "< 네가 부러워 . <EOS>\n",
      "\n",
      "> You'll soon get used to the noise .\n",
      "= 넌 곧 소음에 익숙해질거야 .\n",
      "< 넌 곧 소음에 익숙해질거야 . <EOS>\n",
      "\n",
      "> Would you mind answering a few questions ?\n",
      "= 몇 가지 질문에 답할 의향 있어 ?\n",
      "< 몇 몇 질문에 답할 있니 ? <EOS>\n",
      "\n",
      "> How many of the people here are teachers ?\n",
      "= 여기에 있는 사람 중 몇명이 선생님이야 ?\n",
      "< 여기에 있는 사람 중 몇명이 선생님이야 ? <EOS>\n",
      "\n",
      "> Step back .\n",
      "= 물러서 .\n",
      "< 물러서 . <EOS>\n",
      "\n",
      "> Oh no !\n",
      "= 아니 이런 !\n",
      "< 아니 이런 ! <EOS>\n",
      "\n",
      "> He came out of the shower naked .\n",
      "= 그는 알몸으로 샤워실에서 나왔다 .\n",
      "< 그는 알몸으로 샤워실에서 나왔다 . <EOS>\n",
      "\n",
      "> Tom knows that we can't do that .\n",
      "= 톰은 우리가 저건 할 수 없다는 것을 알고 있어 .\n",
      "< 톰은 우리가 저건 할 수 없다는 것을 알고 있어 . <EOS>\n",
      "\n",
      "> You should try this . It's delicious .\n",
      "= 너 이거 한번 맛봐야해 . 이거 맛있거든 .\n",
      "< 너 이거 한번 맛봐야해 . 이거 . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1, n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnKN_78Xnd-Y"
   },
   "source": [
    "## **5. 마무리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFhPGTe7nmtP"
   },
   "source": [
    "---\n",
    "> 지금까지 NLP의 대표적 과제 중 하나인 기계번역을 Seq2Seq와 Attention 기법을 활용하여 수행해보았습니다. 저도 개인적으로 딥러닝을 활용한 자연어처리를 해본 적이 없어서 Pytorch의 튜토리얼을 바탕으로 실습 내용을 구성하며 많은 공부가 된 것 같습니다. 데이터의 크기가 매우 작다는 점, 그리고 가장 간단한 구조를 사용했다는 점에서 실제 대화에서 오가는 표현을 번역하는 것에는 무리가 있을 것입니다. 하지만, Encoder-Decoder가 어떻게 구현되는지, RNN 게열의 모델은 pytorch에서 어떻게 사용할 수 있는지를 알아볼 수 있었습니다. 이 부분도 2주차 실습과 더불어 한 줄 한 줄 복습해보시기 바랍니다!\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4UvSrkEnh6z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
